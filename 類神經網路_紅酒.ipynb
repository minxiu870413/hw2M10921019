{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyPyWWx5WOSNHfISrDjQM6Fd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"J4ZlwjqfPAVj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605678632758,"user_tz":-480,"elapsed":2618,"user":{"displayName":"丁俞文","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3_QDyvhkNEsasyJsYroZDKubvA3oekgHyzj94TKM=s64","userId":"15674143330167028790"}},"outputId":"a5a8d374-e97b-446d-860f-084254493560"},"source":["# 下載 file_id 為 \"1ktkXrA7sxCpvBbubaPcbRH5CZN0NIX8x\" 的檔案，並將它命名為 winequality-red.csv\n","!gdown --id '1ktkXrA7sxCpvBbubaPcbRH5CZN0NIX8x' --output datasets\n","# 列出目前目錄下所有的檔案\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1ktkXrA7sxCpvBbubaPcbRH5CZN0NIX8x\n","To: /content/datasets\n","\r  0% 0.00/85.7k [00:00<?, ?B/s]\r100% 85.7k/85.7k [00:00<00:00, 32.6MB/s]\n","datasets  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AYWXZHW6RpKZ","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1605678634622,"user_tz":-480,"elapsed":922,"user":{"displayName":"丁俞文","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3_QDyvhkNEsasyJsYroZDKubvA3oekgHyzj94TKM=s64","userId":"15674143330167028790"}},"outputId":"a1e83fd3-3558-438b-b9f6-3a1a85a682bc"},"source":["import pandas as pd\n","\n","import numpy as np\n","df = pd.read_csv('datasets')\n","df.head()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fixed acidity</th>\n","      <th>volatile acidity</th>\n","      <th>citric acid</th>\n","      <th>residual sugar</th>\n","      <th>chlorides</th>\n","      <th>free sulfur dioxide</th>\n","      <th>total sulfur dioxide</th>\n","      <th>density</th>\n","      <th>pH</th>\n","      <th>sulphates</th>\n","      <th>alcohol</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.9978</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7.8</td>\n","      <td>0.88</td>\n","      <td>0.00</td>\n","      <td>2.6</td>\n","      <td>0.098</td>\n","      <td>25.0</td>\n","      <td>67.0</td>\n","      <td>0.9968</td>\n","      <td>3.20</td>\n","      <td>0.68</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7.8</td>\n","      <td>0.76</td>\n","      <td>0.04</td>\n","      <td>2.3</td>\n","      <td>0.092</td>\n","      <td>15.0</td>\n","      <td>54.0</td>\n","      <td>0.9970</td>\n","      <td>3.26</td>\n","      <td>0.65</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.2</td>\n","      <td>0.28</td>\n","      <td>0.56</td>\n","      <td>1.9</td>\n","      <td>0.075</td>\n","      <td>17.0</td>\n","      <td>60.0</td>\n","      <td>0.9980</td>\n","      <td>3.16</td>\n","      <td>0.58</td>\n","      <td>9.8</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.9978</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n","0            7.4              0.70         0.00  ...       0.56      9.4        5\n","1            7.8              0.88         0.00  ...       0.68      9.8        5\n","2            7.8              0.76         0.04  ...       0.65      9.8        5\n","3           11.2              0.28         0.56  ...       0.58      9.8        6\n","4            7.4              0.70         0.00  ...       0.56      9.4        5\n","\n","[5 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"code","metadata":{"id":"8s8NOCkOQVn9"},"source":["#!ls\n","\n","from sklearn.model_selection import train_test_split\n","import keras\n","import keras.utils\n","from keras import utils as np_utils\n","from keras.utils.np_utils import to_categorical\n","y=df['quality']\n","x=df.drop('quality',axis=1)\n","\n","x_train,x_test,y_train,y_test = train_test_split\\\n","(x,y,test_size=0.2)\n","x_train_normalize=x_train/255  #標準化\n","x_test_normalize=x_test/255\n","y_train_onehot = np_utils.to_categorical(y_train)  #one_hot轉換\n","y_test_onehot = np_utils.to_categorical(y_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VF3puvMCUDdy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605678639345,"user_tz":-480,"elapsed":1164,"user":{"displayName":"丁俞文","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3_QDyvhkNEsasyJsYroZDKubvA3oekgHyzj94TKM=s64","userId":"15674143330167028790"}},"outputId":"a97d3524-d2c1-46dc-a7c1-4d4206bfd09a"},"source":["arr=df\n","print(arr.ndim)\n","print(arr.shape)\n","print(arr.dtypes)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2\n","(1599, 12)\n","fixed acidity           float64\n","volatile acidity        float64\n","citric acid             float64\n","residual sugar          float64\n","chlorides               float64\n","free sulfur dioxide     float64\n","total sulfur dioxide    float64\n","density                 float64\n","pH                      float64\n","sulphates               float64\n","alcohol                 float64\n","quality                   int64\n","dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xFpy1TumWY5G","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1605678641713,"user_tz":-480,"elapsed":916,"user":{"displayName":"丁俞文","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3_QDyvhkNEsasyJsYroZDKubvA3oekgHyzj94TKM=s64","userId":"15674143330167028790"}},"outputId":"33786c6c-dcf9-4905-87bb-7e4512c50cb5"},"source":["x_train1D=np.asarray(x_train_normalize).astype('float32')\n","x_test1D=np.asarray(x_test_normalize).astype('float32')\n","y_train1D=np.asarray(y_train_onehot).astype('float32')\n","y_test1D=np.asarray(y_test_onehot).astype('float32')\n","array=x_train\n","array"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fixed acidity</th>\n","      <th>volatile acidity</th>\n","      <th>citric acid</th>\n","      <th>residual sugar</th>\n","      <th>chlorides</th>\n","      <th>free sulfur dioxide</th>\n","      <th>total sulfur dioxide</th>\n","      <th>density</th>\n","      <th>pH</th>\n","      <th>sulphates</th>\n","      <th>alcohol</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>823</th>\n","      <td>6.7</td>\n","      <td>0.54</td>\n","      <td>0.13</td>\n","      <td>2.0</td>\n","      <td>0.076</td>\n","      <td>15.0</td>\n","      <td>36.0</td>\n","      <td>0.99730</td>\n","      <td>3.61</td>\n","      <td>0.64</td>\n","      <td>9.8</td>\n","    </tr>\n","    <tr>\n","      <th>374</th>\n","      <td>14.0</td>\n","      <td>0.41</td>\n","      <td>0.63</td>\n","      <td>3.8</td>\n","      <td>0.089</td>\n","      <td>6.0</td>\n","      <td>47.0</td>\n","      <td>1.00140</td>\n","      <td>3.01</td>\n","      <td>0.81</td>\n","      <td>10.8</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>8.3</td>\n","      <td>0.61</td>\n","      <td>0.30</td>\n","      <td>2.1</td>\n","      <td>0.084</td>\n","      <td>11.0</td>\n","      <td>50.0</td>\n","      <td>0.99720</td>\n","      <td>3.40</td>\n","      <td>0.61</td>\n","      <td>10.2</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>8.6</td>\n","      <td>0.38</td>\n","      <td>0.36</td>\n","      <td>3.0</td>\n","      <td>0.081</td>\n","      <td>30.0</td>\n","      <td>119.0</td>\n","      <td>0.99700</td>\n","      <td>3.20</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","    </tr>\n","    <tr>\n","      <th>759</th>\n","      <td>8.8</td>\n","      <td>0.42</td>\n","      <td>0.21</td>\n","      <td>2.5</td>\n","      <td>0.092</td>\n","      <td>33.0</td>\n","      <td>88.0</td>\n","      <td>0.99823</td>\n","      <td>3.19</td>\n","      <td>0.52</td>\n","      <td>9.2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>804</th>\n","      <td>8.4</td>\n","      <td>0.52</td>\n","      <td>0.22</td>\n","      <td>2.7</td>\n","      <td>0.084</td>\n","      <td>4.0</td>\n","      <td>18.0</td>\n","      <td>0.99682</td>\n","      <td>3.26</td>\n","      <td>0.57</td>\n","      <td>9.9</td>\n","    </tr>\n","    <tr>\n","      <th>333</th>\n","      <td>8.4</td>\n","      <td>0.56</td>\n","      <td>0.08</td>\n","      <td>2.1</td>\n","      <td>0.105</td>\n","      <td>16.0</td>\n","      <td>44.0</td>\n","      <td>0.99580</td>\n","      <td>3.13</td>\n","      <td>0.52</td>\n","      <td>11.0</td>\n","    </tr>\n","    <tr>\n","      <th>409</th>\n","      <td>12.5</td>\n","      <td>0.46</td>\n","      <td>0.49</td>\n","      <td>4.5</td>\n","      <td>0.070</td>\n","      <td>26.0</td>\n","      <td>49.0</td>\n","      <td>0.99810</td>\n","      <td>3.05</td>\n","      <td>0.57</td>\n","      <td>9.6</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>8.8</td>\n","      <td>0.41</td>\n","      <td>0.64</td>\n","      <td>2.2</td>\n","      <td>0.093</td>\n","      <td>9.0</td>\n","      <td>42.0</td>\n","      <td>0.99860</td>\n","      <td>3.54</td>\n","      <td>0.66</td>\n","      <td>10.5</td>\n","    </tr>\n","    <tr>\n","      <th>653</th>\n","      <td>9.4</td>\n","      <td>0.33</td>\n","      <td>0.59</td>\n","      <td>2.8</td>\n","      <td>0.079</td>\n","      <td>9.0</td>\n","      <td>30.0</td>\n","      <td>0.99760</td>\n","      <td>3.12</td>\n","      <td>0.54</td>\n","      <td>12.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1279 rows × 11 columns</p>\n","</div>"],"text/plain":["     fixed acidity  volatile acidity  citric acid  ...    pH  sulphates  alcohol\n","823            6.7              0.54         0.13  ...  3.61       0.64      9.8\n","374           14.0              0.41         0.63  ...  3.01       0.81     10.8\n","100            8.3              0.61         0.30  ...  3.40       0.61     10.2\n","53             8.6              0.38         0.36  ...  3.20       0.56      9.4\n","759            8.8              0.42         0.21  ...  3.19       0.52      9.2\n","..             ...               ...          ...  ...   ...        ...      ...\n","804            8.4              0.52         0.22  ...  3.26       0.57      9.9\n","333            8.4              0.56         0.08  ...  3.13       0.52     11.0\n","409           12.5              0.46         0.49  ...  3.05       0.57      9.6\n","75             8.8              0.41         0.64  ...  3.54       0.66     10.5\n","653            9.4              0.33         0.59  ...  3.12       0.54     12.0\n","\n","[1279 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":120}]},{"cell_type":"code","metadata":{"id":"nu6HvVYUHn3l"},"source":["from keras.models import Sequential #在使用前需要先提前導入這個函數\n","model = Sequential()\n","from keras.layers import Dense\n","\"\"\"\n","    建立輸入層和第一層隱蔽層\n","    \n","    參數：\n","        units - 隱蔽層神經元個數\n","        input_dim - 輸入層神經元個數\n","        kernel_initializer - 使用normal distribution正態分佈的隨機數來初始化權重和方差\n","        activation - 定義激活函數\n","\"\"\"\n","model.add(Dense(units = 224,  \n","                input_dim = 11,  \n","                kernel_initializer = 'normal',  \n","                activation = 'relu'))  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oxkzMZ67Tcbr"},"source":["from keras.layers import Dropout\n","model.add(Dropout(0.5)) #隨機消除50%的神經單元"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2VB6AExTTgOq"},"source":["\"\"\"\n","    建立輸出層\n","    \n","    參數：\n","        units - 輸出層神經元個數\n","        kernel_initializer - 使用normal distribution正態分佈的隨機數來初始化權重和方差\n","        activation - 定義激活函數\n","\"\"\"\n","model.add(Dense(units = 9,\n","                kernel_initializer = 'normal',\n","                activation = 'softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CLeccMqETnoa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605678650787,"user_tz":-480,"elapsed":991,"user":{"displayName":"丁俞文","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3_QDyvhkNEsasyJsYroZDKubvA3oekgHyzj94TKM=s64","userId":"15674143330167028790"}},"outputId":"c763b6d2-38fb-4701-cdb2-f7ac41fc3c1d"},"source":["print(model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_14 (Dense)             (None, 224)               2688      \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 224)               0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 9)                 2025      \n","=================================================================\n","Total params: 4,713\n","Trainable params: 4,713\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SBZ_8GWJT2_S"},"source":["\"\"\"\n","    定義訓練方式\n","\n","    參數：\n","        loss - 損失函數： 這裏採用交叉熵的方式\n","        optimizer - 優化器: 使用adam優化器可以讓訓練收斂更快\n","        metrics - 評估模型：設置爲準確率\n","\n","\"\"\"\n","model.compile(loss = 'categorical_crossentropy',  \n","                     optimizer = 'adam', metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P6EWF7T2ULQ6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605679103199,"user_tz":-480,"elapsed":78078,"user":{"displayName":"丁俞文","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3_QDyvhkNEsasyJsYroZDKubvA3oekgHyzj94TKM=s64","userId":"15674143330167028790"}},"outputId":"300455e6-5fbd-4c79-e88d-91545dd876e3"},"source":["\"\"\"\n","    開始訓練\n","\n","    參數：\n","        X_train_normalize - feature數字圖像的特徵值\n","        y_train_one_hot - 數字圖像的真實標籤\n","        metrics - 評估模型：設置爲準確率\n","        validation_spli - 訓練與驗證數據比例：80%用作訓練數據，20%用作驗證數據\n","        epochs - 訓練週期\n","        batch_size - 每批次的數據項數\n","        verbose - 顯示訓練過程\n","\"\"\"\n","model.fit(x=x_train1D,y=y_train1D,validation_split=0.2,\n","                          epochs=100,batch_size=10,verbose=1)"],"execution_count":144,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.1037 - accuracy: 0.5093 - val_loss: 1.0816 - val_accuracy: 0.5273\n","Epoch 2/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.0967 - accuracy: 0.5230 - val_loss: 1.0690 - val_accuracy: 0.5430\n","Epoch 3/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.0920 - accuracy: 0.5112 - val_loss: 1.0660 - val_accuracy: 0.5547\n","Epoch 4/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.0943 - accuracy: 0.5122 - val_loss: 1.0787 - val_accuracy: 0.5273\n","Epoch 5/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.0904 - accuracy: 0.5191 - val_loss: 1.0685 - val_accuracy: 0.5352\n","Epoch 6/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.0876 - accuracy: 0.5279 - val_loss: 1.0700 - val_accuracy: 0.5273\n","Epoch 7/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.0823 - accuracy: 0.5288 - val_loss: 1.0736 - val_accuracy: 0.5273\n","Epoch 8/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.0855 - accuracy: 0.5191 - val_loss: 1.0617 - val_accuracy: 0.5391\n","Epoch 9/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0810 - accuracy: 0.5210 - val_loss: 1.0569 - val_accuracy: 0.5391\n","Epoch 10/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0737 - accuracy: 0.5406 - val_loss: 1.0619 - val_accuracy: 0.5312\n","Epoch 11/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0763 - accuracy: 0.5367 - val_loss: 1.0534 - val_accuracy: 0.5547\n","Epoch 12/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0881 - accuracy: 0.5191 - val_loss: 1.0691 - val_accuracy: 0.5625\n","Epoch 13/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0817 - accuracy: 0.5269 - val_loss: 1.0887 - val_accuracy: 0.5234\n","Epoch 14/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0765 - accuracy: 0.5318 - val_loss: 1.0533 - val_accuracy: 0.5547\n","Epoch 15/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0727 - accuracy: 0.5298 - val_loss: 1.0462 - val_accuracy: 0.5469\n","Epoch 16/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.0589 - accuracy: 0.5386 - val_loss: 1.0571 - val_accuracy: 0.5469\n","Epoch 17/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0839 - accuracy: 0.5298 - val_loss: 1.0444 - val_accuracy: 0.5586\n","Epoch 18/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0570 - accuracy: 0.5503 - val_loss: 1.0394 - val_accuracy: 0.5469\n","Epoch 19/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0664 - accuracy: 0.5308 - val_loss: 1.0414 - val_accuracy: 0.5469\n","Epoch 20/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0581 - accuracy: 0.5474 - val_loss: 1.0369 - val_accuracy: 0.5469\n","Epoch 21/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0646 - accuracy: 0.5288 - val_loss: 1.0366 - val_accuracy: 0.5391\n","Epoch 22/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0674 - accuracy: 0.5308 - val_loss: 1.0656 - val_accuracy: 0.5117\n","Epoch 23/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0656 - accuracy: 0.5396 - val_loss: 1.0301 - val_accuracy: 0.5664\n","Epoch 24/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0553 - accuracy: 0.5415 - val_loss: 1.0409 - val_accuracy: 0.5742\n","Epoch 25/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0570 - accuracy: 0.5376 - val_loss: 1.0394 - val_accuracy: 0.5625\n","Epoch 26/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0498 - accuracy: 0.5406 - val_loss: 1.0242 - val_accuracy: 0.5586\n","Epoch 27/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0542 - accuracy: 0.5367 - val_loss: 1.0656 - val_accuracy: 0.5195\n","Epoch 28/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0528 - accuracy: 0.5503 - val_loss: 1.0329 - val_accuracy: 0.5508\n","Epoch 29/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0568 - accuracy: 0.5523 - val_loss: 1.0460 - val_accuracy: 0.5508\n","Epoch 30/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0456 - accuracy: 0.5552 - val_loss: 1.0492 - val_accuracy: 0.5430\n","Epoch 31/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0378 - accuracy: 0.5523 - val_loss: 1.0174 - val_accuracy: 0.5391\n","Epoch 32/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0451 - accuracy: 0.5552 - val_loss: 1.0278 - val_accuracy: 0.5664\n","Epoch 33/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0507 - accuracy: 0.5318 - val_loss: 1.0412 - val_accuracy: 0.5508\n","Epoch 34/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0350 - accuracy: 0.5494 - val_loss: 1.0118 - val_accuracy: 0.5508\n","Epoch 35/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0360 - accuracy: 0.5386 - val_loss: 1.0124 - val_accuracy: 0.5469\n","Epoch 36/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0433 - accuracy: 0.5533 - val_loss: 1.0138 - val_accuracy: 0.5547\n","Epoch 37/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0363 - accuracy: 0.5406 - val_loss: 1.0220 - val_accuracy: 0.5625\n","Epoch 38/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0314 - accuracy: 0.5679 - val_loss: 1.0022 - val_accuracy: 0.5547\n","Epoch 39/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0297 - accuracy: 0.5503 - val_loss: 1.0057 - val_accuracy: 0.5742\n","Epoch 40/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0228 - accuracy: 0.5630 - val_loss: 1.0153 - val_accuracy: 0.5703\n","Epoch 41/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0347 - accuracy: 0.5464 - val_loss: 1.0043 - val_accuracy: 0.5625\n","Epoch 42/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0292 - accuracy: 0.5582 - val_loss: 0.9982 - val_accuracy: 0.5586\n","Epoch 43/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0324 - accuracy: 0.5484 - val_loss: 1.0044 - val_accuracy: 0.5625\n","Epoch 44/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0269 - accuracy: 0.5572 - val_loss: 1.0153 - val_accuracy: 0.5625\n","Epoch 45/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0311 - accuracy: 0.5591 - val_loss: 0.9933 - val_accuracy: 0.5586\n","Epoch 46/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.0226 - accuracy: 0.5611 - val_loss: 0.9953 - val_accuracy: 0.5547\n","Epoch 47/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0310 - accuracy: 0.5611 - val_loss: 0.9963 - val_accuracy: 0.5625\n","Epoch 48/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0371 - accuracy: 0.5562 - val_loss: 0.9880 - val_accuracy: 0.5859\n","Epoch 49/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.0266 - accuracy: 0.5611 - val_loss: 0.9908 - val_accuracy: 0.5625\n","Epoch 50/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0202 - accuracy: 0.5582 - val_loss: 0.9863 - val_accuracy: 0.5586\n","Epoch 51/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0151 - accuracy: 0.5679 - val_loss: 0.9976 - val_accuracy: 0.5703\n","Epoch 52/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0209 - accuracy: 0.5621 - val_loss: 0.9938 - val_accuracy: 0.5703\n","Epoch 53/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0122 - accuracy: 0.5611 - val_loss: 0.9798 - val_accuracy: 0.5547\n","Epoch 54/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0263 - accuracy: 0.5523 - val_loss: 0.9811 - val_accuracy: 0.5625\n","Epoch 55/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0176 - accuracy: 0.5523 - val_loss: 0.9855 - val_accuracy: 0.5625\n","Epoch 56/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0208 - accuracy: 0.5611 - val_loss: 0.9768 - val_accuracy: 0.5820\n","Epoch 57/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0186 - accuracy: 0.5640 - val_loss: 1.0020 - val_accuracy: 0.5586\n","Epoch 58/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0218 - accuracy: 0.5689 - val_loss: 1.0105 - val_accuracy: 0.5664\n","Epoch 59/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0200 - accuracy: 0.5650 - val_loss: 0.9788 - val_accuracy: 0.5625\n","Epoch 60/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0187 - accuracy: 0.5640 - val_loss: 0.9778 - val_accuracy: 0.5625\n","Epoch 61/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0107 - accuracy: 0.5679 - val_loss: 0.9860 - val_accuracy: 0.5781\n","Epoch 62/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0130 - accuracy: 0.5630 - val_loss: 0.9885 - val_accuracy: 0.5742\n","Epoch 63/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0059 - accuracy: 0.5709 - val_loss: 0.9737 - val_accuracy: 0.5859\n","Epoch 64/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0058 - accuracy: 0.5689 - val_loss: 0.9943 - val_accuracy: 0.5742\n","Epoch 65/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0129 - accuracy: 0.5640 - val_loss: 0.9683 - val_accuracy: 0.5938\n","Epoch 66/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0179 - accuracy: 0.5709 - val_loss: 0.9665 - val_accuracy: 0.5977\n","Epoch 67/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0070 - accuracy: 0.5591 - val_loss: 0.9957 - val_accuracy: 0.5703\n","Epoch 68/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0025 - accuracy: 0.5689 - val_loss: 0.9658 - val_accuracy: 0.5625\n","Epoch 69/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0177 - accuracy: 0.5533 - val_loss: 0.9664 - val_accuracy: 0.5664\n","Epoch 70/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0147 - accuracy: 0.5630 - val_loss: 0.9663 - val_accuracy: 0.5586\n","Epoch 71/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0031 - accuracy: 0.5601 - val_loss: 0.9670 - val_accuracy: 0.5664\n","Epoch 72/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.0029 - accuracy: 0.5699 - val_loss: 0.9664 - val_accuracy: 0.5742\n","Epoch 73/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0103 - accuracy: 0.5484 - val_loss: 0.9649 - val_accuracy: 0.5938\n","Epoch 74/100\n","512/512 [==============================] - 1s 1ms/step - loss: 0.9986 - accuracy: 0.5679 - val_loss: 0.9671 - val_accuracy: 0.5820\n","Epoch 75/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0035 - accuracy: 0.5582 - val_loss: 0.9615 - val_accuracy: 0.5859\n","Epoch 76/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0059 - accuracy: 0.5601 - val_loss: 0.9806 - val_accuracy: 0.5898\n","Epoch 77/100\n","512/512 [==============================] - 1s 1ms/step - loss: 0.9948 - accuracy: 0.5630 - val_loss: 0.9706 - val_accuracy: 0.5859\n","Epoch 78/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0024 - accuracy: 0.5611 - val_loss: 0.9556 - val_accuracy: 0.5977\n","Epoch 79/100\n","512/512 [==============================] - 1s 1ms/step - loss: 0.9978 - accuracy: 0.5621 - val_loss: 0.9550 - val_accuracy: 0.5703\n","Epoch 80/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0095 - accuracy: 0.5601 - val_loss: 0.9558 - val_accuracy: 0.5938\n","Epoch 81/100\n","512/512 [==============================] - 1s 1ms/step - loss: 0.9996 - accuracy: 0.5523 - val_loss: 0.9611 - val_accuracy: 0.5664\n","Epoch 82/100\n","512/512 [==============================] - 1s 1ms/step - loss: 0.9981 - accuracy: 0.5591 - val_loss: 0.9958 - val_accuracy: 0.5586\n","Epoch 83/100\n","512/512 [==============================] - 1s 2ms/step - loss: 1.0011 - accuracy: 0.5660 - val_loss: 0.9651 - val_accuracy: 0.5898\n","Epoch 84/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0051 - accuracy: 0.5699 - val_loss: 0.9585 - val_accuracy: 0.5664\n","Epoch 85/100\n","512/512 [==============================] - 1s 2ms/step - loss: 0.9904 - accuracy: 0.5826 - val_loss: 0.9569 - val_accuracy: 0.5781\n","Epoch 86/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0042 - accuracy: 0.5582 - val_loss: 0.9842 - val_accuracy: 0.5703\n","Epoch 87/100\n","512/512 [==============================] - 1s 1ms/step - loss: 0.9898 - accuracy: 0.5777 - val_loss: 0.9690 - val_accuracy: 0.5664\n","Epoch 88/100\n","512/512 [==============================] - 1s 2ms/step - loss: 0.9958 - accuracy: 0.5718 - val_loss: 0.9601 - val_accuracy: 0.5703\n","Epoch 89/100\n","512/512 [==============================] - 1s 1ms/step - loss: 0.9946 - accuracy: 0.5748 - val_loss: 0.9665 - val_accuracy: 0.5664\n","Epoch 90/100\n","512/512 [==============================] - 1s 1ms/step - loss: 0.9919 - accuracy: 0.5875 - val_loss: 0.9498 - val_accuracy: 0.5820\n","Epoch 91/100\n","512/512 [==============================] - 1s 1ms/step - loss: 0.9950 - accuracy: 0.5582 - val_loss: 0.9942 - val_accuracy: 0.5625\n","Epoch 92/100\n","512/512 [==============================] - 1s 1ms/step - loss: 0.9938 - accuracy: 0.5699 - val_loss: 0.9510 - val_accuracy: 0.5859\n","Epoch 93/100\n","512/512 [==============================] - 1s 2ms/step - loss: 0.9981 - accuracy: 0.5650 - val_loss: 0.9723 - val_accuracy: 0.5820\n","Epoch 94/100\n","512/512 [==============================] - 1s 1ms/step - loss: 1.0010 - accuracy: 0.5836 - val_loss: 0.9435 - val_accuracy: 0.5898\n","Epoch 95/100\n","512/512 [==============================] - 1s 1ms/step - loss: 0.9915 - accuracy: 0.5718 - val_loss: 0.9480 - val_accuracy: 0.6016\n","Epoch 96/100\n","512/512 [==============================] - 1s 2ms/step - loss: 0.9792 - accuracy: 0.5699 - val_loss: 0.9632 - val_accuracy: 0.5898\n","Epoch 97/100\n","512/512 [==============================] - 1s 2ms/step - loss: 0.9948 - accuracy: 0.5503 - val_loss: 0.9718 - val_accuracy: 0.5820\n","Epoch 98/100\n","512/512 [==============================] - 1s 1ms/step - loss: 0.9982 - accuracy: 0.5591 - val_loss: 0.9848 - val_accuracy: 0.5586\n","Epoch 99/100\n","512/512 [==============================] - 1s 2ms/step - loss: 0.9930 - accuracy: 0.5679 - val_loss: 0.9575 - val_accuracy: 0.5898\n","Epoch 100/100\n","512/512 [==============================] - 1s 2ms/step - loss: 0.9929 - accuracy: 0.5650 - val_loss: 0.9604 - val_accuracy: 0.5859\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f9978d87ac8>"]},"metadata":{"tags":[]},"execution_count":144}]},{"cell_type":"code","metadata":{"id":"A38UpXEDWAo8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605679108025,"user_tz":-480,"elapsed":1098,"user":{"displayName":"丁俞文","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3_QDyvhkNEsasyJsYroZDKubvA3oekgHyzj94TKM=s64","userId":"15674143330167028790"}},"outputId":"330534c0-c45c-4df1-bce4-96080f6b4488"},"source":["# 評估模型的準確率\n","scores = model.evaluate(x_test1D, y_test1D)\n","print()\n","print('accuracy=',scores[1])"],"execution_count":145,"outputs":[{"output_type":"stream","text":["10/10 [==============================] - 0s 2ms/step - loss: 1.0145 - accuracy: 0.5594\n","\n","accuracy= 0.559374988079071\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oGhTyuEb5OG8","executionInfo":{"status":"ok","timestamp":1605678971195,"user_tz":-480,"elapsed":954,"user":{"displayName":"丁俞文","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3_QDyvhkNEsasyJsYroZDKubvA3oekgHyzj94TKM=s64","userId":"15674143330167028790"}}},"source":["y_predict = model.predict(x_test1D)"],"execution_count":140,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GH8pXEQd5PLj","executionInfo":{"status":"ok","timestamp":1605678703250,"user_tz":-480,"elapsed":1094,"user":{"displayName":"丁俞文","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3_QDyvhkNEsasyJsYroZDKubvA3oekgHyzj94TKM=s64","userId":"15674143330167028790"}},"outputId":"72a6ddfc-084b-4e73-b376-01b8e8620eba"},"source":["from sklearn import metrics\n","\n","metrics.mean_squared_error(y_test1D,y_predict)\n","print('RMSE：', np.sqrt(metrics.mean_squared_error(y_test1D,y_predict)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RMSE： 0.26665398\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VgoFDVCuLS3R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605678706818,"user_tz":-480,"elapsed":1526,"user":{"displayName":"丁俞文","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3_QDyvhkNEsasyJsYroZDKubvA3oekgHyzj94TKM=s64","userId":"15674143330167028790"}},"outputId":"3b782e9d-fad9-4ba9-9e13-35383e4dc359"},"source":["def mape(y_test, y_predict):\n","    return np.mean(np.abs((y_predict - y_test1D) / (y_test1D +1))) * 100\n","print('MAPE:',mape(y_test1D, y_predict))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MAPE: 10.580568015575409\n"],"name":"stdout"}]}]}